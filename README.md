# **🔍 AI Resume Screening System**
**An AI-powered resume screening system that intelligently analyzes resumes, extracts key details, and predicts the most suitable job roles based on skills, experience, and education.**  

## **🚀 Overview**
Recruiters spend countless hours reviewing resumes manually, which is **inefficient and time-consuming**. This **AI-driven system automates the screening process** by:  
✅ **Extracting information from resumes** (PDF, DOCX, Images)  
✅ **Predicting best-matched job roles** using **Machine Learning & NLP**  
✅ **Generating structured resume datasets** for improved analysis  

## **🌟 Key Features**
- 📂 **Upload resumes** in **PDF, DOCX, JPG, PNG** formats  
- 🤖 **AI-based resume parsing** (Name, Experience, Education, Skills)  
- 📊 **Predicts best job roles** using **ML & NLP** techniques  
- 📈 **Prepares structured resume data for analysis & visualization**  
- 🔍 **Extracts text from images using OCR (Optical Character Recognition)**  
- 🏆 **Ranks candidates based on job descriptions**  

---

## **🛠️ Tech Stack**
| Technology | Usage |
|------------|-------|
| **Python** | Core programming language |
| **Streamlit** | Interactive UI for resume analysis |
| **Flask** | Backend API |
| **spaCy** | NLP for resume parsing |
| **BERT / TF-IDF** | Text feature extraction |
| **Scikit-learn** | ML model training |
| **PyMuPDF (fitz)** | PDF text extraction |
| **python-docx** | DOCX text extraction |
| **pytesseract (OCR)** | Extract text from images |
| **Pandas & NumPy** | Data handling |
| **Matplotlib & Seaborn** | Data visualization |
| **MongoDB / PostgreSQL** | Database for storing resumes |
---

## **📂 Dataset & Resume Processing**
### **1️⃣ Resume Extraction & Parsing**
- PDFs are processed using **PyMuPDF**  
- DOCX files are parsed using **python-docx**  
- Images (JPG, PNG) are processed via **Tesseract OCR**  

### **2️⃣ Job Role Prediction**
- The extracted text is analyzed using **TF-IDF vectorization**  
- A trained **machine learning model** predicts job roles  
- **Top 3-6 job roles** are selected based on probability scores  

### **3️⃣ Resume Dataset Generation**
- The `generate_csv.py` script creates **synthetic resume datasets**  
- Includes **job title, skills, experience, education, location, etc.**  
- Useful for **model training and analysis**  

---

## **🧠 Algorithms Used**
### **📌 NLP Techniques**
✔ **spaCy** for Named Entity Recognition (NER)  
✔ **TF-IDF Vectorization** for feature extraction  
✔ **BERT-based embeddings** for contextual similarity  

### **📌 Machine Learning Models**
✔ **Logistic Regression** (Baseline model)  
✔ **Random Forest Classifier** (For skill matching)  
✔ **XGBoost (Gradient Boosting)** (For ranking resumes)  
✔ **SVM (Support Vector Machine)** (For suitability classification)  

### **📌 Deep Learning Model (Optional)**
✔ **BiLSTM / BERT-based Model** for **semantic job-resume matching**  

---

## **📦 Installation & Setup**
### **🔹 Step 1: Clone the Repository**
```bash
git clone https://github.com/yourusername/AI-Resume-Screening.git
cd AI-Resume-Screening
```

### **🔹 Step 2: Create a Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate      # Windows
```

### **🔹 Step 3: Install Dependencies**
```bash
pip install -r requirements.txt
```

### **🔹 Step 4: Run the Application**
```bash
streamlit run app.py
```
Open **`http://localhost:8501/`** in your browser.

---

## **📊 Sample Data Visualization**
The resume dataset generated by `generate_csv.py` can be used for **data visualization & insights**.  
- **Top skills per job role**  
- **Candidate experience distribution**  
- **Resume word clouds**  
- **Skill-job match distribution**  



## **🖥️ API Endpoints**
| **Method** | **Endpoint** | **Description** |
|-----------|-------------|----------------|
| `POST` | `/upload` | Upload resume file |
| `GET` | `/resumes` | Retrieve all parsed resumes |
| `POST` | `/match` | Get best candidates for a job |
| `DELETE` | `/resume/<id>` | Delete a resume |

---

## **🤝 Contribution Guidelines**
✅ Fork the repo  
✅ Create a new branch (`git checkout -b feature-name`)  
✅ Commit your changes (`git commit -m "Added feature XYZ"`)  
✅ Push to GitHub (`git push origin feature-name`)  
✅ Open a **Pull Request**  

---
